{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Workflow\n",
    "\n",
    "1. Load and explore the data\n",
    "2. Preprocess the data\n",
    "3. Extract features\n",
    "4. Train the model\n",
    "5. Evaluate the model\n",
    "6. Analyze model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import TypeAlias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"/Users/johnhuang/Desktop/coding/Bag_of_Words/Data\"\n",
    "FILEPATH = f\"{FOLDER}/Tweets_5K.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: str) -> tuple[list[str], list[int]]:\n",
    "    \"\"\"\n",
    "    Loads Twitter data into two lists.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    raw_tweets : list[str]\n",
    "        A list of all Tweets in the dataset\n",
    "    labels : list[int]\n",
    "        A list of the sentiments corresponding to each raw tweet encoded as integers,\n",
    "        -1 meaning negative, 0 meaning neutral, and 1 meaning positive\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(filepath)\n",
    "    raw_tweets = dataset[\"text\"].astype(str).tolist()\n",
    "    labels=[]\n",
    "    for label in dataset[\"sentiment\"].astype(str).tolist():\n",
    "      if label == \"neutral\":\n",
    "        labels.append(0)\n",
    "      elif label == \"negative\":\n",
    "        labels.append(-1)\n",
    "      else:\n",
    "        labels.append(1)\n",
    "    return (raw_tweets, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets, labels = load_data(FILEPATH)\n",
    "for p, label in zip(raw_tweets[:10], labels[:10]):\n",
    "    print(f\"{label}:\\t{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Plot Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "pd.Series(labels).value_counts().plot.bar(title=\"Sentiment Distribution in Tweets\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Initial Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_X: list[str]) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Performs splitting on whitespace on all raw strings in a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_X : list[str]\n",
    "        A list of raw strings (tweets)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[str]]\n",
    "        A list of preprocessed tweets (which are now lists of words)\n",
    "    \"\"\"\n",
    "    preprocessed_tweets = []\n",
    "    for string in raw_X:\n",
    "      preprocessed_tweets.append(string.split())\n",
    "    return preprocessed_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Featurization and Train and Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class BOW_Classifier:\n",
    "    \"\"\"\n",
    "    Attributes\n",
    "    ----------\n",
    "    clf : LogisticRegression\n",
    "        A logistic regression classifier\n",
    "    dv : DictVectorizer\n",
    "        A dictionary vectorizer for turning dictionaries into matrices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.clf = LogisticRegression(max_iter=150)\n",
    "        self.dv = DictVectorizer()\n",
    "\n",
    "    def featurize(self, preproc_X: np.ndarray[list[str]], is_test: bool = False) -> csr_matrix:\n",
    "        \"\"\"\n",
    "        Turns a list of preprocessed tweets into a binary bag-of-words matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        preproc_X : np.ndarray[list[str]]\n",
    "            A list of preprocessed tweets\n",
    "        is_test: bool, default=False\n",
    "            Whether featurization should be done using features learned during training (is_test=True)\n",
    "            or whether it should be done with features extracted from scratch using preproc_X (is_test=False)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        csr_matrix\n",
    "            A matrix with rows corresponding to tweets and columns corresponding to words\n",
    "        \"\"\"\n",
    "        vocab = []\n",
    "        for string in preproc_X:\n",
    "          tweet_dict = {}\n",
    "          for word in string:\n",
    "            tweet_dict[word] = 1\n",
    "          vocab.append(tweet_dict)\n",
    "        if is_test:\n",
    "          matrix = self.dv.transform(vocab)\n",
    "        else:\n",
    "          matrix = self.dv.fit_transform(vocab)\n",
    "        return matrix\n",
    "\n",
    "    def train(self, X_train: np.ndarray[list[str]], y_train: np.ndarray[int]):\n",
    "        \"\"\"\n",
    "        Trains the BOW classifier on the given training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray[list[str]]\n",
    "            Preprocessed tweets for training\n",
    "        y_train : np.ndarray[int]\n",
    "            Sentiments corresponding to the tweets in X_train\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        BoW_matrix = self.featurize(X_train, is_test = False)\n",
    "        self.clf.fit(BoW_matrix, y_train)\n",
    "\n",
    "    def test(self, X_test: np.ndarray[list[str]]) -> np.ndarray[int]:\n",
    "        \"\"\"\n",
    "        Classifies the given test data and returns predicted sentiments.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test : np.ndarray[list[str]]\n",
    "            Preprocessed tweets for testing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : np.ndarray[int]\n",
    "            Predicted sentiments for the tweets in X_test\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        BoW_test_matrix = self.featurize(X_test, is_test = True)\n",
    "        return self.clf.predict(BoW_test_matrix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
